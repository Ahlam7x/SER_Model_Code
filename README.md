# SER_Model_Code
This repository implements a Speech Emotion Recognition (SER) model inspired by Original Repository transformer-cnn-emotion-recognition. Our contribution includes integrating a Co-Attention mechanism to effectively combine features from multiple models to three diverse datasets. 


## üìå Overview  
This repository contains the implementation of a **Speech Emotion Recognition (SER) model** that integrates a **Co-Attention mechanism** to enhance feature fusion from multiple models.  

üîç **Inspired by** [transformer-cnn-emotion-recognition](https://github.com/IliaZenkov/transformer-cnn-emotion-recognition) by Ilia Zenkov, we extend the architecture by:  
- **Adding Co-Attention:** To combine features from different models.  
- **Applying on Three Datasets:** ASVP-ESD V1, ASVP-ESD V2, and ShEmo for broader evaluation.  
 
## üìú Acknowledgement  

This work is inspired by [transformer-cnn-emotion-recognition](https://github.com/IliaZenkov/transformer-cnn-emotion-recognition) by **Ilia Zenkov**.

### Our Contributions:
- **Co-Attention Integration:** Added a Co-Attention mechanism for advanced feature fusion.  
- **Multi-Dataset Application:** Applied the model on ASVP-ESD V1, ASVP-ESD V2, and ShEmo datasets.  
- **Improved Accuracy:** Enhanced emotion classification by combining MFCC and Mel spectrogram features.  
